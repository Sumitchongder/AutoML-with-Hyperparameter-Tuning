{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODTehzAWZZ2PAEtOvssrik",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sumitchongder/AutoML-with-Hyperparameter-Tuning/blob/main/AutoML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RnRJfsphknQ"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import base64\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "#---------------------------------#\n",
        "# Page layout\n",
        "## Page expands to full width\n",
        "st.set_page_config(page_title='The Machine Learning Hyperparameter Optimization App',\n",
        "    layout='wide')\n",
        "\n",
        "#---------------------------------#\n",
        "st.write(\"\"\"\n",
        "# The Machine Learning Hyperparameter Optimization App\n",
        "**(Regression Edition)**\n",
        "In this implementation, the *RandomForestRegressor()* function is used in this app for build a regression model using the **Random Forest** algorithm.\n",
        "\"\"\")\n",
        "\n",
        "#---------------------------------#\n",
        "# Sidebar - Collects user input features into dataframe\n",
        "st.sidebar.header('Upload your CSV data')\n",
        "uploaded_file = st.sidebar.file_uploader(\"Upload your input CSV file\", type=[\"csv\"])\n",
        "st.sidebar.markdown(\"\"\"\n",
        "[Example CSV input file](https://raw.githubusercontent.com/dataprofessor/data/master/delaney_solubility_with_descriptors.csv)\n",
        "\"\"\")\n",
        "\n",
        "# Sidebar - Specify parameter settings\n",
        "st.sidebar.header('Set Parameters')\n",
        "split_size = st.sidebar.slider('Data split ratio (% for Training Set)', 10, 90, 80, 5)\n",
        "\n",
        "st.sidebar.subheader('Learning Parameters')\n",
        "parameter_n_estimators = st.sidebar.slider('Number of estimators (n_estimators)', 0, 500, (10,50), 50)\n",
        "parameter_n_estimators_step = st.sidebar.number_input('Step size for n_estimators', 10)\n",
        "st.sidebar.write('---')\n",
        "parameter_max_features = st.sidebar.slider('Max features (max_features)', 1, 50, (1,3), 1)\n",
        "st.sidebar.number_input('Step size for max_features', 1)\n",
        "st.sidebar.write('---')\n",
        "parameter_min_samples_split = st.sidebar.slider('Minimum number of samples required to split an internal node (min_samples_split)', 1, 10, 2, 1)\n",
        "parameter_min_samples_leaf = st.sidebar.slider('Minimum number of samples required to be at a leaf node (min_samples_leaf)', 1, 10, 2, 1)\n",
        "\n",
        "st.sidebar.subheader('General Parameters')\n",
        "parameter_random_state = st.sidebar.slider('Seed number (random_state)', 0, 1000, 42, 1)\n",
        "parameter_criterion = st.sidebar.select_slider('Performance measure (criterion)', options=['mse', 'mae'])\n",
        "parameter_bootstrap = st.sidebar.select_slider('Bootstrap samples when building trees (bootstrap)', options=[True, False])\n",
        "parameter_oob_score = st.sidebar.select_slider('Whether to use out-of-bag samples to estimate the R^2 on unseen data (oob_score)', options=[False, True])\n",
        "parameter_n_jobs = st.sidebar.select_slider('Number of jobs to run in parallel (n_jobs)', options=[1, -1])\n",
        "\n",
        "n_estimators_range = np.arange(parameter_n_estimators[0], parameter_n_estimators[1]+parameter_n_estimators_step, parameter_n_estimators_step)\n",
        "max_features_range = np.arange(parameter_max_features[0], parameter_max_features[1]+1, 1)\n",
        "param_grid = dict(max_features=max_features_range, n_estimators=n_estimators_range)\n",
        "\n",
        "#---------------------------------#\n",
        "# Main panel\n",
        "\n",
        "# Displays the dataset\n",
        "st.subheader('Dataset')\n",
        "\n",
        "#---------------------------------#\n",
        "# Model building\n",
        "\n",
        "def filedownload(df):\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode()).decode()  # strings <-> bytes conversions\n",
        "    href = f'<a href=\"data:file/csv;base64,{b64}\" download=\"model_performance.csv\">Download CSV File</a>'\n",
        "    return href\n",
        "\n",
        "def build_model(df):\n",
        "    X = df.iloc[:,:-1] # Using all column except for the last column as X\n",
        "    Y = df.iloc[:,-1] # Selecting the last column as Y\n",
        "\n",
        "    st.markdown('A model is being built to predict the following **Y** variable:')\n",
        "    st.info(Y.name)\n",
        "\n",
        "    # Data splitting\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=split_size)\n",
        "    #X_train.shape, Y_train.shape\n",
        "    #X_test.shape, Y_test.shape\n",
        "\n",
        "    rf = RandomForestRegressor(n_estimators=parameter_n_estimators,\n",
        "        random_state=parameter_random_state,\n",
        "        max_features=parameter_max_features,\n",
        "        criterion=parameter_criterion,\n",
        "        min_samples_split=parameter_min_samples_split,\n",
        "        min_samples_leaf=parameter_min_samples_leaf,\n",
        "        bootstrap=parameter_bootstrap,\n",
        "        oob_score=parameter_oob_score,\n",
        "        n_jobs=parameter_n_jobs)\n",
        "\n",
        "    grid = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5)\n",
        "    grid.fit(X_train, Y_train)\n",
        "\n",
        "    st.subheader('Model Performance')\n",
        "\n",
        "    Y_pred_test = grid.predict(X_test)\n",
        "    st.write('Coefficient of determination ($R^2$):')\n",
        "    st.info( r2_score(Y_test, Y_pred_test) )\n",
        "\n",
        "    st.write('Error (MSE or MAE):')\n",
        "    st.info( mean_squared_error(Y_test, Y_pred_test) )\n",
        "\n",
        "    st.write(\"The best parameters are %s with a score of %0.2f\"\n",
        "      % (grid.best_params_, grid.best_score_))\n",
        "\n",
        "    st.subheader('Model Parameters')\n",
        "    st.write(grid.get_params())\n",
        "\n",
        "    #-----Process grid data-----#\n",
        "    grid_results = pd.concat([pd.DataFrame(grid.cv_results_[\"params\"]),pd.DataFrame(grid.cv_results_[\"mean_test_score\"], columns=[\"R2\"])],axis=1)\n",
        "    # Segment data into groups based on the 2 hyperparameters\n",
        "    grid_contour = grid_results.groupby(['max_features','n_estimators']).mean()\n",
        "    # Pivoting the data\n",
        "    grid_reset = grid_contour.reset_index()\n",
        "    grid_reset.columns = ['max_features', 'n_estimators', 'R2']\n",
        "    grid_pivot = grid_reset.pivot('max_features', 'n_estimators')\n",
        "    x = grid_pivot.columns.levels[1].values\n",
        "    y = grid_pivot.index.values\n",
        "    z = grid_pivot.values\n",
        "\n",
        "    #-----Plot-----#\n",
        "    layout = go.Layout(\n",
        "            xaxis=go.layout.XAxis(\n",
        "              title=go.layout.xaxis.Title(\n",
        "              text='n_estimators')\n",
        "             ),\n",
        "             yaxis=go.layout.YAxis(\n",
        "              title=go.layout.yaxis.Title(\n",
        "              text='max_features')\n",
        "            ) )\n",
        "    fig = go.Figure(data= [go.Surface(z=z, y=y, x=x)], layout=layout )\n",
        "    fig.update_layout(title='Hyperparameter tuning',\n",
        "                      scene = dict(\n",
        "                        xaxis_title='n_estimators',\n",
        "                        yaxis_title='max_features',\n",
        "                        zaxis_title='R2'),\n",
        "                      autosize=False,\n",
        "                      width=800, height=800,\n",
        "                      margin=dict(l=65, r=50, b=65, t=90))\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    #-----Save grid data-----#\n",
        "    x = pd.DataFrame(x)\n",
        "    y = pd.DataFrame(y)\n",
        "    z = pd.DataFrame(z)\n",
        "    df = pd.concat([x,y,z], axis=1)\n",
        "    st.markdown(filedownload(grid_results), unsafe_allow_html=True)\n",
        "\n",
        "#---------------------------------#\n",
        "if uploaded_file is not None:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "    st.write(df)\n",
        "    build_model(df)\n",
        "else:\n",
        "    st.info('Awaiting for CSV file to be uploaded.')\n",
        "    if st.button('Press to use Example Dataset'):\n",
        "        diabetes = load_diabetes()\n",
        "        X = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
        "        Y = pd.Series(diabetes.target, name='response')\n",
        "        df = pd.concat( [X,Y], axis=1 )\n",
        "\n",
        "        st.markdown('The **Diabetes** dataset is used as the example.')\n",
        "        st.write(df.head(5))\n",
        "\n",
        "        build_model(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FLMrkNm6h8Cw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}